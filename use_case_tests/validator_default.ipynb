{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "965dba60-7c5b-43bc-8df1-6e745093ed14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Google AI API key:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f10d752f-e239-42c1-abc1-2a2feef3b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "truth_df = pd.read_excel('/home/jupyter/CPE_EVAL/ground_truth.xlsx')\n",
    "extract_df = pd.read_excel('/home/jupyter/CPE_EVAL/extraction_gemini.xlsx')\n",
    "\n",
    "# Read the spreadsheets\n",
    "table1 = truth_df\n",
    "table2 = extract_df\n",
    "\n",
    "table1_name = \"truth\"\n",
    "table2_name = \"extraction\"\n",
    "\n",
    "# using col names of table1 for table 2; Attention: make sure order is the same!\n",
    "table2.columns = table1.columns\n",
    "\n",
    "# Sorting the tables by 'Authors' column\n",
    "table1_sorted = table1.sort_values(by=\"filename\").reset_index(drop=True)\n",
    "table2_sorted = table2.sort_values(by=\"filename\").reset_index(drop=True)\n",
    "\n",
    "# Strip any leading or trailing whitespace from all column names\n",
    "table1_sorted.columns = table1_sorted.columns.str.strip()\n",
    "table2_sorted.columns = table2_sorted.columns.str.strip()\n",
    "\n",
    "# DROP ‘filename’\n",
    "table1_sorted = table1_sorted.drop('filename', axis=1)\n",
    "table2_sorted = table2_sorted.drop('filename', axis=1)\n",
    "\n",
    "# Create an empty DataFrame to store the comparison results\n",
    "columns = table1_sorted.columns\n",
    "comparison_results = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Initialize confusion matrices\n",
    "confusion_matrices = {col: {\"Correct\": 0, \"Incorrect\": 0, \"False Positive\": 0, \"False Negative\": 0} for col in columns}\n",
    "\n",
    "# Initialize a DataFrame to store the highlighted differences for table2\n",
    "table2_highlighted = table2_sorted.copy()\n",
    "\n",
    "class ColumnProcessor:\n",
    "    def process(self, value):\n",
    "        raise NotImplementedError(\"Subclasses should implement this!\")\n",
    "\n",
    "    def compare(self, val1, val2):\n",
    "        raise NotImplementedError(\"Subclasses should implement this!\")\n",
    "\n",
    "    # Higlight the differences was an optional feature to higlight the found\n",
    "    # differences between Truth and User cases\n",
    "    # def highlight_differences(self, val1, val2):\n",
    "    #     raise NotImplementedError(\"Subclasses should implement this!\")\n",
    "\n",
    "class StringColumnProcessor(ColumnProcessor):\n",
    "    def process(self, value):\n",
    "        if pd.isna(value) or value == \"N/A\":\n",
    "            return \"\"\n",
    "        return str(value).replace(\" \", \"\").replace(\".\", \"\").replace(\",\", \"\").lower()\n",
    "\n",
    "    def compare(self, val1, val2):\n",
    "        if val1 == \"\" and val2 != \"\":\n",
    "            return \"False Positive\"\n",
    "        elif val1 != \"\" and val2 == \"\":\n",
    "            return \"False Negative\"\n",
    "        similarity = SequenceMatcher(None, val1, val2).ratio()\n",
    "        return \"Correct\" if similarity == 1 else \"Incorrect\"\n",
    "\n",
    "class StringColumnNoisyProcessor(ColumnProcessor):\n",
    "    def process(self, value):\n",
    "        if pd.isna(value) or value == \"N/A\":\n",
    "            return \"\"\n",
    "        return str(value).replace(\" \", \"\").replace(\".\", \"\").replace(\",\", \"\").lower()\n",
    "\n",
    "    def compare(self, val1, val2):\n",
    "        if val1 == \"\" and val2 != \"\":\n",
    "            return \"False Positive\"\n",
    "        elif val1 != \"\" and val2 == \"\":\n",
    "            return \"False Negative\"\n",
    "        similarity = SequenceMatcher(None, val1, val2).ratio()\n",
    "        return \"Correct\" if similarity > 0.75 else \"Incorrect\"\n",
    "\n",
    "    def highlight_differences(self, val1, val2):\n",
    "        matcher = SequenceMatcher(None, val1, val2)\n",
    "        highlighted_val2 = []\n",
    "        for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
    "            if tag == 'equal':\n",
    "                highlighted_val2.append(val2[j1:j2])\n",
    "            elif tag == 'replace' or tag == 'delete' or tag == 'insert':\n",
    "                highlighted_val2.append(f\"[{val2[j1:j2]}]\")\n",
    "        return ''.join(highlighted_val2)\n",
    "\n",
    "class ListColumnProcessor(ColumnProcessor):\n",
    "    def process(self, value):\n",
    "        # 1) Handle blanks/N/A as an empty list\n",
    "        if pd.isna(value) or str(value).strip().upper() == \"N/A\":\n",
    "            return []\n",
    "        # 2) Split on commas into items\n",
    "        raw = str(value)\n",
    "        items = []\n",
    "        for part in raw.split(','):\n",
    "            # strip whitespace and surrounding punctuation, lowercase\n",
    "            clean = part.strip().lower().strip(\" .;:()[]{}\\\"'\")\n",
    "            if clean:\n",
    "                items.append(clean)\n",
    "        return items\n",
    "\n",
    "    def compare(self, truth_list, comp_list):\n",
    "        # 1) both empty → Correct\n",
    "        if not truth_list and not comp_list:\n",
    "            return \"Correct\"\n",
    "        # 2) truth empty vs comp nonempty → FP\n",
    "        if not truth_list and comp_list:\n",
    "            return \"False Positive\"\n",
    "        # 3) truth nonempty vs comp empty → FN\n",
    "        if truth_list and not comp_list:\n",
    "            return \"False Negative\"\n",
    "        # 4) both nonempty → set logic\n",
    "        truth_set = set(truth_list)\n",
    "        comp_set  = set(comp_list)\n",
    "        missing = truth_set - comp_set\n",
    "        extra   = comp_set - truth_set\n",
    "\n",
    "        if not missing and not extra:\n",
    "            return \"Correct\"\n",
    "        if extra and not missing:\n",
    "            return \"False Positive\"\n",
    "        if missing and not extra:\n",
    "            return \"False Negative\"\n",
    "        return \"Incorrect\"\n",
    "\n",
    "class BooleanListColumnProcessor(ColumnProcessor):\n",
    "    def process(self, value):\n",
    "        # Normalize missing\n",
    "        if pd.isna(value) or str(value).strip().upper() == \"N/A\":\n",
    "            return []\n",
    "        raw = str(value)\n",
    "        # Split on standalone “OR”\n",
    "        parts = re.split(r'\\bOR\\b', raw, flags=re.IGNORECASE)\n",
    "        alternatives = []\n",
    "        for part in parts:\n",
    "            # Now split on commas into a list of strings\n",
    "            items = [item.strip().lower() \n",
    "                     for item in part.split(',') \n",
    "                     if item.strip()]\n",
    "            alternatives.append(items)\n",
    "        # If only one alternative, just return that list\n",
    "        if len(alternatives) == 1:\n",
    "            return alternatives[0]\n",
    "        # Otherwise, return list-of-alternative-lists\n",
    "        return alternatives\n",
    "\n",
    "    def compare(self, truth_list, comp_list):\n",
    "        # Handle empty‐vs‐nonempty\n",
    "        if not truth_list and comp_list:\n",
    "            return \"False Positive\"\n",
    "        if truth_list and not comp_list:\n",
    "            return \"False Negative\"\n",
    "        if not truth_list and not comp_list:\n",
    "            return \"Correct\"\n",
    "\n",
    "        # If truth_list is a list of alternatives\n",
    "        if (isinstance(truth_list, list) and truth_list and\n",
    "            isinstance(truth_list[0], list)):\n",
    "            # Try each alternative in turn\n",
    "            for alt in truth_list:\n",
    "                result = self._compare_single(alt, comp_list)\n",
    "                if result == \"Correct\":\n",
    "                    return \"Correct\"\n",
    "                # Otherwise keep track of FP/FN if they occur\n",
    "                if result in (\"False Positive\", \"False Negative\"):\n",
    "                    last_fp_fn = result\n",
    "            return last_fp_fn if 'last_fp_fn' in locals() else \"Incorrect\"\n",
    "\n",
    "        # Otherwise it's a single list -> compare directly\n",
    "        return self._compare_single(truth_list, comp_list)\n",
    "\n",
    "    def _compare_single(self, truth_items, comp_items):\n",
    "        truth_set = set(truth_items)\n",
    "        comp_set  = set(comp_items)\n",
    "        missing = truth_set - comp_set\n",
    "        extra   = comp_set - truth_set\n",
    "\n",
    "        if not missing and not extra:\n",
    "            return \"Correct\"\n",
    "        if extra and not missing:\n",
    "            return \"False Positive\"\n",
    "        if missing and not extra:\n",
    "            return \"False Negative\"\n",
    "        return \"Incorrect\"\n",
    "\n",
    "class KeywordListColumnProcessor(ColumnProcessor):\n",
    "    def process(self, value):\n",
    "        # Treat blanks/N/A as “no keywords”\n",
    "        if pd.isna(value) or str(value).strip().upper() == \"N/A\":\n",
    "            return []\n",
    "        raw = str(value)\n",
    "        # Split on commas into candidate keywords\n",
    "        parts = [part.strip() for part in raw.split(\",\")]\n",
    "        keywords = []\n",
    "        for part in parts:\n",
    "            # Remove everything except letters+digits, lowercase\n",
    "            clean = re.sub(r'[^A-Za-z0-9]', '', part).lower()\n",
    "            if clean:\n",
    "                keywords.append(clean)\n",
    "        return keywords\n",
    "\n",
    "    def compare(self, truth_keywords, comp_keywords):\n",
    "        # Edge cases: empty vs non-empty\n",
    "        if not truth_keywords and comp_keywords:\n",
    "            return \"False Positive\"\n",
    "        if truth_keywords and not comp_keywords:\n",
    "            return \"False Negative\"\n",
    "        if not truth_keywords and not comp_keywords:\n",
    "            return \"Correct\"\n",
    "\n",
    "        # Check that every truth‐keyword appears in *some* comp string\n",
    "        missing = [\n",
    "            kw for kw in truth_keywords\n",
    "            if not any(kw in comp for comp in comp_keywords)\n",
    "        ]\n",
    "        return \"Correct\" if not missing else \"False Negative\"\n",
    "\n",
    "class OrderedListColumnProcessor(ListColumnProcessor):\n",
    "    def compare(self, truth_list, comparison_list):\n",
    "        if truth_list == \"\" and comparison_list != \"\":\n",
    "            return \"False Positive\"\n",
    "        elif truth_list != \"\" and comparison_list == \"\":\n",
    "            return \"False Negative\"\n",
    "        if not truth_list or not comparison_list:\n",
    "            return \"Incorrect\"\n",
    "\n",
    "        # Convert the lists to sets to compare their contents\n",
    "        truth_set = set(truth_list)\n",
    "        comparison_set = set(comparison_list)\n",
    "\n",
    "        # Check for missing elements in the second list (False Negative)\n",
    "        missing_elements = truth_set - comparison_set\n",
    "\n",
    "        # Check for extra elements in the second list (False Positive)\n",
    "        extra_elements = comparison_set - truth_set\n",
    "\n",
    "        # If both missing and extra elements exist, treat it as Incorrect\n",
    "        if missing_elements and extra_elements:\n",
    "            return \"Incorrect\"\n",
    "\n",
    "        # If there are only extra elements in the second list (False Positive)\n",
    "        if extra_elements:\n",
    "            return \"False Positive\"\n",
    "\n",
    "        # If there are only missing elements in the second list (False Negative)\n",
    "        if missing_elements:\n",
    "            return \"False Negative\"\n",
    "\n",
    "        # Check if the lists have the same elements but in the wrong order (Incorrect)\n",
    "        if truth_list != comparison_list:\n",
    "            return \"Incorrect\"\n",
    "\n",
    "        # If both lists are exactly the same in content and order, return Correct\n",
    "        return \"Correct\"\n",
    "\n",
    "class NumericColumnProcessor(ColumnProcessor):\n",
    "    # def process(self, value):\n",
    "    #     if pd.isna(value) or value == \"N/A\":\n",
    "    #         return \"\"\n",
    "    #     try:\n",
    "    #         # Round the numeric value to the first digit after the comma\n",
    "    #         value = round(float(value), 1)\n",
    "    #     except ValueError:\n",
    "    #         pass\n",
    "    #     return ''.join(filter(str.isdigit, str(value)))\n",
    "\n",
    "# rewritten process function\n",
    "    def process(self,value):\n",
    "        if pd.isna(value) or value == \"N/A\":\n",
    "            return \"\"\n",
    "\n",
    "        # Use regular expressions to find numeric parts in the string\n",
    "        match = re.search(r\"\\d+(\\.\\d+)?\", str(value))\n",
    "\n",
    "        if match:\n",
    "            # Convert the matched number to float and round to one decimal place\n",
    "            number = round(float(match.group()), 1)\n",
    "\n",
    "            # Return the number as a string with one decimal place\n",
    "            return str(number)\n",
    "\n",
    "        # Return empty string if no numeric part is found\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "\n",
    "    def compare(self, val1, val2):\n",
    "        if val1 == \"\" and val2 != \"\":\n",
    "            return \"False Positive\"\n",
    "        elif val1 != \"\" and val2 == \"\":\n",
    "            return \"False Negative\"\n",
    "        elif val1 == \"\" and val2 == \"\":\n",
    "            return \"Correct\"\n",
    "        elif val1 != \"\" and val2 != \"\":\n",
    "       #similarity = SequenceMatcher(None, val1, val2).ratio() # can try other metrics later on\n",
    "          num1=float(val1)\n",
    "          num2=float(val2)\n",
    "          if num1 == num2:\n",
    "            return \"Correct\"\n",
    "          else:\n",
    "            return \"Incorrect\"\n",
    "\n",
    "    # def highlight_differences(self, val1, val2):\n",
    "    #     return val2  # No complex highlighting for numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a51d490b-ec94-4648-8968-0be198f62eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "class LLMColumnProcessor(ColumnProcessor):\n",
    "    def __init__(self, model_name=\"gemini-2.5-flash-preview-04-17\"):\n",
    "        # Define the structured output: just a yes/no field\n",
    "        response_schemas = [\n",
    "            ResponseSchema(\n",
    "                name=\"match\",\n",
    "                description='“yes” if the two values are semantically equivalent, otherwise “no”'\n",
    "            )\n",
    "        ]\n",
    "        self.parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "        format_instructions = self.parser.get_format_instructions()\n",
    "\n",
    "        fi = self.parser.get_format_instructions()\n",
    "# turn every single-brace into a double-brace so f-string PromptTemplate treats\n",
    "# them as *literal* braces\n",
    "        fi_escaped = fi.replace('{', '{{').replace('}', '}}')\n",
    "\n",
    "        prompt_template = (\n",
    "            \"You are evaluating data extraction.  Given the ground truth value:\\n\\n\"\n",
    "            \"  {truth}\\n\\n\"\n",
    "            \"and the extracted value:\\n\\n\"\n",
    "            \"  {extracted}\\n\\n\"\n",
    "            \"Decide whether they convey the same meaning (even if phrased differently).\\n\"\n",
    "            f\"{fi_escaped}\\n\"\n",
    "        )\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "        # Use ChatOpenAI for chat models\n",
    "        llm = ChatGoogleGenerativeAI(model=model_name, temperature=0)\n",
    "\n",
    "        # Chain prompt and chat model\n",
    "        self.chain = prompt | llm\n",
    "\n",
    "    def process(self, value):\n",
    "        if pd.isna(value) or str(value).strip().upper() == \"N/A\":\n",
    "            return \"\"\n",
    "        return str(value)\n",
    "\n",
    "    def compare(self, truth_val, extracted_val):\n",
    "        if truth_val.strip().lower() == extracted_val.strip().lower():\n",
    "            return \"Correct\"\n",
    "        if not truth_val and not extracted_val:\n",
    "            return \"Correct\"\n",
    "        if not truth_val and extracted_val:\n",
    "            return \"False Positive\"\n",
    "        if truth_val and not extracted_val:\n",
    "            return \"False Negative\"\n",
    "\n",
    "        raw = self.chain.invoke({\"truth\": truth_val, \"extracted\": extracted_val})\n",
    "        parsed = self.parser.parse(raw.content)  # extract text content here\n",
    "        return \"Correct\" if parsed[\"match\"].strip().lower() == \"yes\" else \"Incorrect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "471ecf04-6134-44fb-bb53-ce6e9d3eb139",
   "metadata": {},
   "outputs": [],
   "source": [
    "processors = {\n",
    "    \"country\": StringColumnProcessor(),\n",
    "    \"type_of_study\": BooleanListColumnProcessor(),\n",
    "    \"sample_type\": BooleanListColumnProcessor(),\n",
    "    \"matrix_description\": LLMColumnProcessor(),\n",
    "    \"bacterial_species\": ListColumnProcessor(),\n",
    "    \"genes\": KeywordListColumnProcessor(),\n",
    "    \"protocol_reference\": KeywordListColumnProcessor(),\n",
    "    \"isolation_procedure\": BooleanListColumnProcessor(),\n",
    "    \"method_validation\": LLMColumnProcessor(),\n",
    "    \"isolate_characterization\": KeywordListColumnProcessor(),\n",
    "    \"MLST_isolates\": ListColumnProcessor(),\n",
    "    \"gene_localization\": ListColumnProcessor(),\n",
    "    \"plasmid_type\": StringColumnProcessor(),\n",
    "    \"plasmid_size\": StringColumnProcessor(),\n",
    "    \"plasmid_transferable\": StringColumnProcessor(),\n",
    "    \"LOD_culture_based\": StringColumnProcessor(),\n",
    "    \"confirmation_carbapenemase\": BooleanListColumnProcessor(), \n",
    "    \"sample_dilution\": StringColumnProcessor(),\n",
    "    \"sample_weight\": StringColumnProcessor(),\n",
    "    \"first_enrichtment\": KeywordListColumnProcessor(),\n",
    "    \"first_enrichtment_condition\": NumericColumnProcessor(),\n",
    "    \"second_enrichment\": BooleanListColumnProcessor(),\n",
    "    \"second_enrichtment_selective\": KeywordListColumnProcessor(),\n",
    "    \"second_enrichtment_condition\": NumericColumnProcessor(),\n",
    "    \"selective_plate\": LLMColumnProcessor(),\n",
    "    \"ncb_method\": KeywordListColumnProcessor(),\n",
    "    \"which_step\": StringColumnNoisyProcessor(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1968511c-823c-48de-8ebb-4600868441e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Results:\n",
      "  country_truth                                 country_extraction  \\\n",
      "0        France  the Netherlands, Sweden, France, Norway, Denma...   \n",
      "1       Germany                                            Germany   \n",
      "2       Germany                                            Germany   \n",
      "3       Germany                                            Germany   \n",
      "4       Germany                                            Germany   \n",
      "5       Germany                                            Germany   \n",
      "6       Germany                                            Germany   \n",
      "7       Germany                                            Germany   \n",
      "\n",
      "  country_comparison                                type_of_study_truth  \\\n",
      "0          Incorrect  method comparison, method validation OR method...   \n",
      "1            Correct                               sample investigation   \n",
      "2            Correct         sample investigation, protocol development   \n",
      "3            Correct                               sample investigation   \n",
      "4            Correct               method comparison, method validation   \n",
      "5            Correct  method comparison, protocol development, metho...   \n",
      "6            Correct                               sample investigation   \n",
      "7            Correct                               sample investigation   \n",
      "\n",
      "                            type_of_study_extraction type_of_study_comparison  \\\n",
      "0               method comparison, method validation                  Correct   \n",
      "1                               sample investigation                  Correct   \n",
      "2  sample investigation, protocol development, me...           False Positive   \n",
      "3     sample investigation, isolate characterization           False Positive   \n",
      "4               method comparison, method validation                  Correct   \n",
      "5  method comparison, method validation, protocol...                  Correct   \n",
      "6                               sample investigation                  Correct   \n",
      "7            sample investigation, method comparison           False Positive   \n",
      "\n",
      "                                   sample_type_truth  \\\n",
      "0                                    livestock, food   \n",
      "1      livestock OR livestock, livestock environment   \n",
      "2                   livestock, livestock environment   \n",
      "3                                               food   \n",
      "4                                    livestock, food   \n",
      "5                                          livestock   \n",
      "6  livestock, livestock environment OR livestock,...   \n",
      "7                   livestock, livestock environment   \n",
      "\n",
      "                              sample_type_extraction sample_type_comparison  \\\n",
      "0                                    livestock, food                Correct   \n",
      "1                   livestock, livestock environment                Correct   \n",
      "2                   livestock, livestock environment                Correct   \n",
      "3             food, livestock, livestock environment         False Positive   \n",
      "4                       livestock, food, aquaculture         False Positive   \n",
      "5                                          livestock                Correct   \n",
      "6  livestock, food, livestock environment, enviro...                Correct   \n",
      "7             livestock, livestock environment, food         False Positive   \n",
      "\n",
      "                            matrix_description_truth  ...  \\\n",
      "0     Pig caecal samples and SPF turkey meat samples  ...   \n",
      "1                                          pig feces  ...   \n",
      "2  Fecal samples from pigs and environmental swab...  ...   \n",
      "3                    Shoulder meat sample from a pig  ...   \n",
      "4                 cecum content, colon content, meat  ...   \n",
      "5                          Pig caeca (fecal) samples  ...   \n",
      "6  Broiler production chain samples including par...  ...   \n",
      "7  Swine samples including feces, boot swabs, and...  ...   \n",
      "\n",
      "  second_enrichtment_condition_comparison  \\\n",
      "0                                 Correct   \n",
      "1                                 Correct   \n",
      "2                               Incorrect   \n",
      "3                          False Negative   \n",
      "4                                 Correct   \n",
      "5                               Incorrect   \n",
      "6                                 Correct   \n",
      "7                                 Correct   \n",
      "\n",
      "                               selective_plate_truth  \\\n",
      "0  Brilliance™ CRE Agar, CHROMID® CARBA Agar, CHR...   \n",
      "1                                                NaN   \n",
      "2  ChromID R Carba plates and MacConkey agar with...   \n",
      "3  McConkey agar with MEM (0.125 mg/L) and CTX (1...   \n",
      "4  ChromID®CARBA agar; MacConkey agar supplemente...   \n",
      "5  chromID® CARBA SMART agar, McC + CTX+MEM, McC ...   \n",
      "6  MacConkey agar no. 3 with 1mg/L  cefotaxime (M...   \n",
      "7  ChromID Carba, MacConkey agar with cefotaxime ...   \n",
      "\n",
      "                          selective_plate_extraction  \\\n",
      "0  Brilliance ™ CRE Agar, CHROMID ® CARBA, CHROMa...   \n",
      "1                                                NaN   \n",
      "2       chromID Carba, MacConkey + 1 mg/L cefotaxime   \n",
      "3  McConkey agar + 0.125 mg/L meropenem, McConkey...   \n",
      "4  ChromID CARBA, MacConkey + cefotaxime 1 mg/L +...   \n",
      "5  chromID CARBA SMART agar, MacConkey agar with ...   \n",
      "6          MacConkey agar with cefotaxime 1 mg/liter   \n",
      "7  ChromID Carba, MacConkey agar with cefotaxime ...   \n",
      "\n",
      "  selective_plate_comparison    ncb_method_truth ncb_method_extraction  \\\n",
      "0                  Incorrect  PCR, real-time PCR                   NaN   \n",
      "1                    Correct                 NaN         real-time PCR   \n",
      "2                    Correct       Real-time PCR         real time PCR   \n",
      "3                  Incorrect       Real-time PCR                   NaN   \n",
      "4                    Correct                 NaN                   NaN   \n",
      "5                    Correct       Real-time PCR         Real-time PCR   \n",
      "6                  Incorrect       Real-time PCR                   NaN   \n",
      "7                  Incorrect       real-time PCR         real time PCR   \n",
      "\n",
      "  ncb_method_comparison                                 which_step_truth  \\\n",
      "0        False Negative                                   post-isolation   \n",
      "1        False Positive                                              NaN   \n",
      "2               Correct              After the selective enrichment step   \n",
      "3        False Negative                                   post-isolation   \n",
      "4               Correct                                              NaN   \n",
      "5               Correct  After first enrichment, After second enrichment   \n",
      "6        False Negative                                   post-isolation   \n",
      "7               Correct                           After first enrichment   \n",
      "\n",
      "                             which_step_extraction which_step_comparison  \n",
      "0                                              NaN        False Negative  \n",
      "1                           After first enrichment        False Positive  \n",
      "2           after first enrichment, post-isolation             Incorrect  \n",
      "3                                              NaN        False Negative  \n",
      "4                                              NaN               Correct  \n",
      "5  After first enrichment, After second enrichment               Correct  \n",
      "6                                              NaN        False Negative  \n",
      "7                           After first enrichment               Correct  \n",
      "\n",
      "[8 rows x 81 columns]\n",
      "\n",
      "Confusion Matrices and Accuracy:\n",
      "                              Correct  Incorrect  False Positive  \\\n",
      "country                           7.0        1.0             0.0   \n",
      "type_of_study                     5.0        0.0             3.0   \n",
      "sample_type                       5.0        0.0             3.0   \n",
      "matrix_description                3.0        5.0             0.0   \n",
      "bacterial_species                 4.0        2.0             2.0   \n",
      "genes                             7.0        0.0             0.0   \n",
      "protocol_reference                7.0        0.0             0.0   \n",
      "isolation_procedure               8.0        0.0             0.0   \n",
      "method_validation                 2.0        2.0             4.0   \n",
      "isolate_characterization          1.0        0.0             0.0   \n",
      "MLST_isolates                     7.0        1.0             0.0   \n",
      "gene_localization                 6.0        1.0             1.0   \n",
      "plasmid_type                      7.0        1.0             0.0   \n",
      "plasmid_size                      6.0        2.0             0.0   \n",
      "plasmid_transferable              6.0        1.0             0.0   \n",
      "LOD_culture_based                 8.0        0.0             0.0   \n",
      "confirmation_carbapenemase        1.0        4.0             2.0   \n",
      "sample_dilution                   7.0        0.0             1.0   \n",
      "sample_weight                     5.0        2.0             1.0   \n",
      "first_enrichtment                 5.0        0.0             2.0   \n",
      "first_enrichtment_condition       7.0        1.0             0.0   \n",
      "second_enrichment                 8.0        0.0             0.0   \n",
      "second_enrichtment_selective      7.0        0.0             0.0   \n",
      "second_enrichtment_condition      5.0        2.0             0.0   \n",
      "selective_plate                   4.0        4.0             0.0   \n",
      "ncb_method                        4.0        0.0             1.0   \n",
      "which_step                        3.0        1.0             1.0   \n",
      "Overall                         145.0       30.0            21.0   \n",
      "\n",
      "                              False Negative  Accuracy  \n",
      "country                                  0.0  0.875000  \n",
      "type_of_study                            0.0  0.625000  \n",
      "sample_type                              0.0  0.625000  \n",
      "matrix_description                       0.0  0.375000  \n",
      "bacterial_species                        0.0  0.500000  \n",
      "genes                                    1.0  0.875000  \n",
      "protocol_reference                       1.0  0.875000  \n",
      "isolation_procedure                      0.0  1.000000  \n",
      "method_validation                        0.0  0.250000  \n",
      "isolate_characterization                 7.0  0.125000  \n",
      "MLST_isolates                            0.0  0.875000  \n",
      "gene_localization                        0.0  0.750000  \n",
      "plasmid_type                             0.0  0.875000  \n",
      "plasmid_size                             0.0  0.750000  \n",
      "plasmid_transferable                     1.0  0.750000  \n",
      "LOD_culture_based                        0.0  1.000000  \n",
      "confirmation_carbapenemase               1.0  0.125000  \n",
      "sample_dilution                          0.0  0.875000  \n",
      "sample_weight                            0.0  0.625000  \n",
      "first_enrichtment                        1.0  0.625000  \n",
      "first_enrichtment_condition              0.0  0.875000  \n",
      "second_enrichment                        0.0  1.000000  \n",
      "second_enrichtment_selective             1.0  0.875000  \n",
      "second_enrichtment_condition             1.0  0.625000  \n",
      "selective_plate                          0.0  0.500000  \n",
      "ncb_method                               3.0  0.500000  \n",
      "which_step                               3.0  0.375000  \n",
      "Overall                                 20.0  0.671296  \n"
     ]
    }
   ],
   "source": [
    "# Process and compare the data\n",
    "for column in columns:\n",
    "    processor = processors[column]\n",
    "    processed_table1 = table1_sorted[column].apply(processor.process)\n",
    "    processed_table2 = table2_sorted[column].apply(processor.process)\n",
    "    comparison_results[column] = [\n",
    "        processor.compare(val1, val2) for val1, val2 in zip(processed_table1, processed_table2)\n",
    "    ]\n",
    "    # table2_highlighted[column] = [\n",
    "    #     processor.highlight_differences(val1, val2) for val1, val2 in zip(processed_table1, processed_table2)\n",
    "    # ]\n",
    "    # Update confusion matrices\n",
    "    for result in comparison_results[column]:\n",
    "        confusion_matrices[column][result] += 1\n",
    "\n",
    "# Combine the analyzed tables with the comparison results in the specified order\n",
    "combined_output = pd.DataFrame()\n",
    "\n",
    "for column in columns:\n",
    "    combined_output[f'{column}_{table1_name}'] = table1_sorted[column]\n",
    "    combined_output[f'{column}_{table2_name}'] = table2_sorted[column]\n",
    "    combined_output[f'{column}_comparison'] = comparison_results[column]\n",
    "\n",
    "### Combined Metrics ### (Additional removed)\n",
    "\n",
    "# Calculate accuracy for each column in the confusion matrices\n",
    "for column, matrix in confusion_matrices.items():\n",
    "    TP = matrix[\"Correct\"]\n",
    "    FP = matrix[\"False Positive\"]\n",
    "    FN = matrix[\"False Negative\"]\n",
    "    N = matrix[\"Incorrect\"]\n",
    "\n",
    "    accuracy = TP / (TP + FP + FN + N) if (TP + FP + FN + N) > 0 else 0\n",
    "\n",
    "    # Store only the accuracy in the matrix\n",
    "    matrix.update({\n",
    "        \"Accuracy\": accuracy\n",
    "    })\n",
    "\n",
    "#### Combined metrics ####\n",
    "\n",
    "# Calculate overall accuracy across all columns\n",
    "overall_metrics = {\"Correct\": 0, \"Incorrect\": 0, \"False Positive\": 0, \"False Negative\": 0}\n",
    "\n",
    "# Sum all the confusion matrix values to get overall metrics\n",
    "for column, matrix in confusion_matrices.items():\n",
    "    if column == \"Overall\":\n",
    "        continue  # Skip if already calculated\n",
    "    overall_metrics[\"Correct\"] += matrix[\"Correct\"]\n",
    "    overall_metrics[\"Incorrect\"] += matrix[\"Incorrect\"]\n",
    "    overall_metrics[\"False Positive\"] += matrix[\"False Positive\"]\n",
    "    overall_metrics[\"False Negative\"] += matrix[\"False Negative\"]\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "TP = overall_metrics[\"Correct\"]\n",
    "FP = overall_metrics[\"False Positive\"]\n",
    "FN = overall_metrics[\"False Negative\"]\n",
    "N = overall_metrics[\"Incorrect\"]\n",
    "\n",
    "overall_accuracy = TP / (TP + FP + FN + N) if (TP + FP + FN + N) > 0 else 0\n",
    "\n",
    "# Store the overall metrics in the matrix\n",
    "overall_metrics.update({\"Accuracy\": overall_accuracy})\n",
    "confusion_matrices[\"Overall\"] = overall_metrics\n",
    "\n",
    "# Convert confusion matrices to DataFrame\n",
    "confusion_matrices_df = pd.DataFrame(confusion_matrices).T\n",
    "\n",
    "# Save the combined output table and confusion matrices to an Excel file\n",
    "with pd.ExcelWriter(f'Comparison_Results_CARC_{table1_name}_{table2_name}.xlsx') as writer:\n",
    "    combined_output.to_excel(writer, sheet_name='Combined Results', index=False)\n",
    "    confusion_matrices_df.to_excel(writer, sheet_name='Confusion Matrices')\n",
    "\n",
    "print(\"Combined Results:\")\n",
    "print(combined_output)\n",
    "\n",
    "print(\"\\nConfusion Matrices and Accuracy:\")\n",
    "print(confusion_matrices_df)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
